{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_RNN_Modele_de_Langage.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Réseaux Recursifs (RNNs) et Modèles de Langage\n",
        "Pour ce TP nous allons explorer les RNNs et notamment les LSTMs. Nous allons essayer d'utiliser un RNN pour apprendre des séquences des mots (un texte) et ensuite générer de nouvelles séquences. \n",
        "\n",
        "Néanmoins, avant cela nous allons examiner la structure basique d'un LSTM en utilisant une entrée aléatoire. Même si plus tard nous allons avoir du texte en entrée, les LSTMs fonctionnent avec des nombres. Nous allons voir plus tard comment passer du texte aux tenseurs. Pour l'instant voici un tenseur 3x8 aléatoire. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V5hmV8eaS9Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "m5XQWEfa7w8q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#entrée\n",
        "x = torch.randint(1, 100, (3, 8))\n",
        "print(x)\n",
        "\n",
        "# torch.randint(low=0, high, size, \\*, generator=None, out=None, dtype=None,\n",
        "#   layout=torch.strided, device=None, requires_grad=False) → Tensor\n"
      ],
      "metadata": {
        "id": "r7DqeDD-o96j",
        "outputId": "c5ea8011-a520-47df-d5fc-7862eecf59fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[66, 10, 46, 24, 59, 19, 32, 82],\n",
            "        [40, 21, 39, 28, 54, 12, 47, 59],\n",
            "        [42, 64, 81, 28, 21,  5, 64, 21]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons passer cet entrée aléatoire à une couche embedding, parce que les embeddings des mots peuvent mieux  representer le contexte et sont plus efficaces que les representations one-hot. \n",
        "\n",
        "Pour Pytorch nous avons besoin d'utiliser `nn.Embedding` afin de créer cette couche, qui prend en entrée la taille du vocabulaire et la longueur de vecteur de mot souhaitée. Vous pouvez éventuellement fournir un index de padding, pour indiquer l'index de l'élément de padding dans la matrice qui va représenter une phrase. Le padding sert à mettre ensemble plusieurs phrases dans un minibatch pour les mettre toutes à la même longueur.\n",
        "\n",
        "\n",
        "Dans l'exemple suivant, notre vocabulaire se compose de 100 mots, incluant l'élément spécial du padding, pour lequel on a choisi de donner l'indice 0.\n",
        "\n",
        "Remarque : dans cet exemple, le padding ne sert pas...\n",
        "\n",
        "Que représente `x` dans notre contexte NLP ? Quelle est la taille des tenseurs issus de `model1` de la cellule suivante ?\n",
        "\n",
        "- _x représente une mise en forme du dictionaire de mots. Le réseau trouve une représentation autour que one-hot._ "
      ],
      "metadata": {
        "id": "b4gWwcV2qQFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = nn.Embedding(100, 7, padding_idx=0)\n",
        "out1 = model1(x)"
      ],
      "metadata": {
        "id": "uXLUDsdtrjH2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous passons la sortie de la couche embedding dans une couche LSTM qui prend en entrée la longeur du vecteur representant le mot, la longueur de la couche cachée, et le nombre des couches. La couche LSTM sort trois choses, à quoi correspondent chacune d'entre elles ? Quelles sont leurs tailles ?\n",
        "\n",
        "- **out** contient la sortie de la denrnière couche du LSTM pour chaque epoch de taille (longeur sequence, 1, taille du batch, nombre d'état de sortie).\n",
        "- **h_n** contient l'état caché final de chaque élément de la séquence de taille (nombre de couches, taille du batch, nombre de couches cachées).\n",
        "- **c_n** contient la mémoire cell finale de chaque élélment de la séquence de taille (nombre de couche, taille du batch, nombre de couches cahcées).\n",
        "\n",
        "_source :_ https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html"
      ],
      "metadata": {
        "id": "bWczP6zGr7-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = nn.LSTM(input_size=7, hidden_size=5, num_layers=1, batch_first=True)\n",
        "\n",
        "out, (ht, ct) = model2(out1)\n"
      ],
      "metadata": {
        "id": "SErXwFhftWgF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passons maintaiannt au modèle de langage. Pour les données nous allons utiliser un ensemble de blagues recueillis sur Reddit, inspiré par un tutoriel de Domas Bitvinskas.   \n",
        "\n",
        "\n",
        "## Le modèle \n",
        "Voici un premier modèle utilisant trois couches LSTM."
      ],
      "metadata": {
        "id": "eA9OqdSCo-8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LfA98RjmS5ZJ"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "C'est un model LSTM avec Pytorch assez standard. Comme expliqué dans l'introduction, le but de la couche `Embedding` est de convertir les mots (leur indice dans un dictionnaire) en vecteurs. La fonction `init_state` est appelée au début de chaque époque.  \n",
        "\n",
        "## Données \n",
        "Téléchargons les données.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YFW6l7vVS7Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amoudgl/short-jokes-dataset/master/data/reddit-cleanjokes.csv"
      ],
      "metadata": {
        "id": "HkyqHu-J-xG-",
        "outputId": "2fca20cf-6e17-40fe-e7ae-78e28b474379",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-13 12:49:26--  https://raw.githubusercontent.com/amoudgl/short-jokes-dataset/master/data/reddit-cleanjokes.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 141847 (139K) [text/plain]\n",
            "Saving to: ‘reddit-cleanjokes.csv’\n",
            "\n",
            "reddit-cleanjokes.c 100%[===================>] 138.52K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-02-13 12:49:26 (60.4 MB/s) - ‘reddit-cleanjokes.csv’ saved [141847/141847]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Il s'agit d'un fichier tsv de la forme `ID,Joke` ou `ID` signifie simplement l'identifiant de la « blague » et `Joke` le texte. Afin de pouvoir traiter les données nous aurons besoin d'utiliser la class `Dataset`\n"
      ],
      "metadata": {
        "id": "D_4Zpmks-tn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  \n",
        "    def __init__(\n",
        "        self,\n",
        "        sequence_length,\n",
        "    ):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "    \n",
        "    def load_words(self):\n",
        "        train_df = pd.read_csv('reddit-cleanjokes.csv')\n",
        "        text = train_df['Joke'].str.cat(sep=' ')\n",
        "        return text.split(' ')\n",
        "    \n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )"
      ],
      "metadata": {
        "id": "Zy0v3k37Xht1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette classe hérite de la classe `torch.utils.data.Dataset`. En plus de `__init__`,  il est nécessaire de définir deux fonctions : `__len__` et `__getitem__`. La première retourne la taille de notre ensemble des données alors que la deuxième implémente l'indexation afin que `dataset[i]` puisse être utilisé pour retourner le *i*-ème élément. Vous pouvez avoir plus de détails [ici](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class). \n",
        "\n",
        "La fonction `load_words` charge le dataset. Le but est de trouver tous les mots afin de définir la taille du vocabulaire du réseau mais également la taille de l'embedding. Deux autres fonctions `index_to_word` et `word_to_index` convertissent les mots en index et vice versa. \n",
        "\n",
        "# Entrainement \n",
        "\n",
        "Nous allons définir une fonction `train` pour entraîner notre RNN. "
      ],
      "metadata": {
        "id": "J3gjVI4UhYxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "\n",
        "def train(dataset, model, max_epochs, sequence_length):\n",
        "    model.train()\n",
        "    dataloader = DataLoader(dataset, batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    for epoch in range(max_epochs):\n",
        "        state_h, state_c = model.init_state(sequence_length)\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
      ],
      "metadata": {
        "id": "tNCaFS1YziKO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme vous pouvez constater la fonction train charge d'abord les données, définit comme fonction de perte Cross Entropy Loss ainsi que SGD comme optimizer et ensuite appelle le modèle pour `max_epochs`. \n",
        "\n",
        "# Prédictions \n",
        "\n",
        "Une fois que nous avons entraîné notre modèle nous pouvons ensuite faire des prédictions, en donnant une séquence des mots en entrée.   Voici une fonction nous permettant de prédire les `next_words` suivant à partir d'un `text`. "
      ],
      "metadata": {
        "id": "mF6YTawU0pg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "    words = text.split(' ')\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "    return words"
      ],
      "metadata": {
        "id": "CuvVMi4F0ptq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous sommes prêtes et prêts maintenant à entraîner notre modèle, ci-dessous un morceau du code qui nous permettra de le faire sur l'ensemble des données."
      ],
      "metadata": {
        "id": "JzDYV1ff0vNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 4\n",
        "max_epochs = 10\n",
        "\n",
        "dataset = Dataset(sequence_length)\n",
        "model = Model(dataset)\n",
        "print(model)\n",
        "train(dataset, model, max_epochs, sequence_length)\n",
        "print(predict(dataset, model, text='One day I shot an elephant in my suit. I have no idea how he got into it.'))"
      ],
      "metadata": {
        "id": "HnhUFjd70vXc",
        "outputId": "a8cd477b-8c7d-4b7b-b047-20f971702bf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (embedding): Embedding(6925, 128)\n",
            "  (lstm): LSTM(128, 128, num_layers=3, dropout=0.2)\n",
            "  (fc): Linear(in_features=128, out_features=6925, bias=True)\n",
            ")\n",
            "{'epoch': 0, 'batch': 0, 'loss': 8.835528373718262}\n",
            "{'epoch': 0, 'batch': 1, 'loss': 8.826991081237793}\n",
            "{'epoch': 0, 'batch': 2, 'loss': 8.824238777160645}\n",
            "{'epoch': 0, 'batch': 3, 'loss': 8.82489013671875}\n",
            "{'epoch': 0, 'batch': 4, 'loss': 8.81036376953125}\n",
            "{'epoch': 0, 'batch': 5, 'loss': 8.797056198120117}\n",
            "{'epoch': 0, 'batch': 6, 'loss': 8.792482376098633}\n",
            "{'epoch': 0, 'batch': 7, 'loss': 8.772226333618164}\n",
            "{'epoch': 0, 'batch': 8, 'loss': 8.73105525970459}\n",
            "{'epoch': 0, 'batch': 9, 'loss': 8.67509651184082}\n",
            "{'epoch': 0, 'batch': 10, 'loss': 8.594453811645508}\n",
            "{'epoch': 0, 'batch': 11, 'loss': 8.471065521240234}\n",
            "{'epoch': 0, 'batch': 12, 'loss': 8.398972511291504}\n",
            "{'epoch': 0, 'batch': 13, 'loss': 8.289005279541016}\n",
            "{'epoch': 0, 'batch': 14, 'loss': 8.08060073852539}\n",
            "{'epoch': 0, 'batch': 15, 'loss': 8.015557289123535}\n",
            "{'epoch': 0, 'batch': 16, 'loss': 7.825394630432129}\n",
            "{'epoch': 0, 'batch': 17, 'loss': 7.782345294952393}\n",
            "{'epoch': 0, 'batch': 18, 'loss': 7.676605701446533}\n",
            "{'epoch': 0, 'batch': 19, 'loss': 7.621140956878662}\n",
            "{'epoch': 0, 'batch': 20, 'loss': 7.361607074737549}\n",
            "{'epoch': 0, 'batch': 21, 'loss': 7.644532203674316}\n",
            "{'epoch': 0, 'batch': 22, 'loss': 7.522946834564209}\n",
            "{'epoch': 0, 'batch': 23, 'loss': 7.654277801513672}\n",
            "{'epoch': 0, 'batch': 24, 'loss': 7.475335121154785}\n",
            "{'epoch': 0, 'batch': 25, 'loss': 7.295999526977539}\n",
            "{'epoch': 0, 'batch': 26, 'loss': 7.221106052398682}\n",
            "{'epoch': 0, 'batch': 27, 'loss': 7.152061939239502}\n",
            "{'epoch': 0, 'batch': 28, 'loss': 7.684183120727539}\n",
            "{'epoch': 0, 'batch': 29, 'loss': 7.755521774291992}\n",
            "{'epoch': 0, 'batch': 30, 'loss': 7.014471530914307}\n",
            "{'epoch': 0, 'batch': 31, 'loss': 7.05470085144043}\n",
            "{'epoch': 0, 'batch': 32, 'loss': 7.2220139503479}\n",
            "{'epoch': 0, 'batch': 33, 'loss': 7.435438632965088}\n",
            "{'epoch': 0, 'batch': 34, 'loss': 7.372844219207764}\n",
            "{'epoch': 0, 'batch': 35, 'loss': 7.69817590713501}\n",
            "{'epoch': 0, 'batch': 36, 'loss': 7.610998153686523}\n",
            "{'epoch': 0, 'batch': 37, 'loss': 7.379206657409668}\n",
            "{'epoch': 0, 'batch': 38, 'loss': 7.672724723815918}\n",
            "{'epoch': 0, 'batch': 39, 'loss': 7.517818927764893}\n",
            "{'epoch': 0, 'batch': 40, 'loss': 7.799249649047852}\n",
            "{'epoch': 0, 'batch': 41, 'loss': 7.401181221008301}\n",
            "{'epoch': 0, 'batch': 42, 'loss': 7.731947898864746}\n",
            "{'epoch': 0, 'batch': 43, 'loss': 7.454376697540283}\n",
            "{'epoch': 0, 'batch': 44, 'loss': 7.301675796508789}\n",
            "{'epoch': 0, 'batch': 45, 'loss': 7.538209915161133}\n",
            "{'epoch': 0, 'batch': 46, 'loss': 7.704380035400391}\n",
            "{'epoch': 0, 'batch': 47, 'loss': 7.9563493728637695}\n",
            "{'epoch': 0, 'batch': 48, 'loss': 7.33302640914917}\n",
            "{'epoch': 0, 'batch': 49, 'loss': 7.676977634429932}\n",
            "{'epoch': 0, 'batch': 50, 'loss': 7.905541896820068}\n",
            "{'epoch': 0, 'batch': 51, 'loss': 7.6059136390686035}\n",
            "{'epoch': 0, 'batch': 52, 'loss': 7.1264872550964355}\n",
            "{'epoch': 0, 'batch': 53, 'loss': 7.4579033851623535}\n",
            "{'epoch': 0, 'batch': 54, 'loss': 7.323178768157959}\n",
            "{'epoch': 0, 'batch': 55, 'loss': 7.409372329711914}\n",
            "{'epoch': 0, 'batch': 56, 'loss': 7.483956813812256}\n",
            "{'epoch': 0, 'batch': 57, 'loss': 7.504210948944092}\n",
            "{'epoch': 0, 'batch': 58, 'loss': 7.446977138519287}\n",
            "{'epoch': 0, 'batch': 59, 'loss': 7.403065204620361}\n",
            "{'epoch': 0, 'batch': 60, 'loss': 7.312248706817627}\n",
            "{'epoch': 0, 'batch': 61, 'loss': 7.481664180755615}\n",
            "{'epoch': 0, 'batch': 62, 'loss': 7.514933109283447}\n",
            "{'epoch': 0, 'batch': 63, 'loss': 7.374061107635498}\n",
            "{'epoch': 0, 'batch': 64, 'loss': 7.489405155181885}\n",
            "{'epoch': 0, 'batch': 65, 'loss': 7.425021171569824}\n",
            "{'epoch': 0, 'batch': 66, 'loss': 7.382648944854736}\n",
            "{'epoch': 0, 'batch': 67, 'loss': 7.207126617431641}\n",
            "{'epoch': 0, 'batch': 68, 'loss': 7.392122745513916}\n",
            "{'epoch': 0, 'batch': 69, 'loss': 7.142114639282227}\n",
            "{'epoch': 0, 'batch': 70, 'loss': 7.577492713928223}\n",
            "{'epoch': 0, 'batch': 71, 'loss': 7.522139549255371}\n",
            "{'epoch': 0, 'batch': 72, 'loss': 7.402003288269043}\n",
            "{'epoch': 0, 'batch': 73, 'loss': 7.505969524383545}\n",
            "{'epoch': 0, 'batch': 74, 'loss': 7.503362655639648}\n",
            "{'epoch': 0, 'batch': 75, 'loss': 7.635232448577881}\n",
            "{'epoch': 0, 'batch': 76, 'loss': 7.394403457641602}\n",
            "{'epoch': 0, 'batch': 77, 'loss': 7.686733722686768}\n",
            "{'epoch': 0, 'batch': 78, 'loss': 7.811429500579834}\n",
            "{'epoch': 0, 'batch': 79, 'loss': 7.040743827819824}\n",
            "{'epoch': 0, 'batch': 80, 'loss': 7.343028545379639}\n",
            "{'epoch': 0, 'batch': 81, 'loss': 7.503844261169434}\n",
            "{'epoch': 0, 'batch': 82, 'loss': 7.5459370613098145}\n",
            "{'epoch': 0, 'batch': 83, 'loss': 7.591409683227539}\n",
            "{'epoch': 0, 'batch': 84, 'loss': 7.355917453765869}\n",
            "{'epoch': 0, 'batch': 85, 'loss': 7.557754993438721}\n",
            "{'epoch': 0, 'batch': 86, 'loss': 7.307747840881348}\n",
            "{'epoch': 0, 'batch': 87, 'loss': 7.403850555419922}\n",
            "{'epoch': 0, 'batch': 88, 'loss': 7.313815116882324}\n",
            "{'epoch': 0, 'batch': 89, 'loss': 7.452036380767822}\n",
            "{'epoch': 0, 'batch': 90, 'loss': 7.802005767822266}\n",
            "{'epoch': 0, 'batch': 91, 'loss': 7.276310920715332}\n",
            "{'epoch': 0, 'batch': 92, 'loss': 7.502087116241455}\n",
            "{'epoch': 0, 'batch': 93, 'loss': 7.158036231994629}\n",
            "{'epoch': 1, 'batch': 0, 'loss': 7.171719551086426}\n",
            "{'epoch': 1, 'batch': 1, 'loss': 7.181879997253418}\n",
            "{'epoch': 1, 'batch': 2, 'loss': 7.118127822875977}\n",
            "{'epoch': 1, 'batch': 3, 'loss': 7.351508140563965}\n",
            "{'epoch': 1, 'batch': 4, 'loss': 7.288098335266113}\n",
            "{'epoch': 1, 'batch': 5, 'loss': 7.299120903015137}\n",
            "{'epoch': 1, 'batch': 6, 'loss': 7.6822509765625}\n",
            "{'epoch': 1, 'batch': 7, 'loss': 7.492791175842285}\n",
            "{'epoch': 1, 'batch': 8, 'loss': 7.399348258972168}\n",
            "{'epoch': 1, 'batch': 9, 'loss': 7.210905075073242}\n",
            "{'epoch': 1, 'batch': 10, 'loss': 7.151172637939453}\n",
            "{'epoch': 1, 'batch': 11, 'loss': 7.0585174560546875}\n",
            "{'epoch': 1, 'batch': 12, 'loss': 7.1128034591674805}\n",
            "{'epoch': 1, 'batch': 13, 'loss': 7.157820701599121}\n",
            "{'epoch': 1, 'batch': 14, 'loss': 6.845499038696289}\n",
            "{'epoch': 1, 'batch': 15, 'loss': 6.942301273345947}\n",
            "{'epoch': 1, 'batch': 16, 'loss': 6.7321062088012695}\n",
            "{'epoch': 1, 'batch': 17, 'loss': 6.909705638885498}\n",
            "{'epoch': 1, 'batch': 18, 'loss': 6.837345123291016}\n",
            "{'epoch': 1, 'batch': 19, 'loss': 6.942190647125244}\n",
            "{'epoch': 1, 'batch': 20, 'loss': 6.670604228973389}\n",
            "{'epoch': 1, 'batch': 21, 'loss': 7.043071269989014}\n",
            "{'epoch': 1, 'batch': 22, 'loss': 7.019299030303955}\n",
            "{'epoch': 1, 'batch': 23, 'loss': 7.120064735412598}\n",
            "{'epoch': 1, 'batch': 24, 'loss': 7.075119495391846}\n",
            "{'epoch': 1, 'batch': 25, 'loss': 6.82358980178833}\n",
            "{'epoch': 1, 'batch': 26, 'loss': 6.816122531890869}\n",
            "{'epoch': 1, 'batch': 27, 'loss': 6.817185878753662}\n",
            "{'epoch': 1, 'batch': 28, 'loss': 7.221993923187256}\n",
            "{'epoch': 1, 'batch': 29, 'loss': 7.321447372436523}\n",
            "{'epoch': 1, 'batch': 30, 'loss': 6.697638988494873}\n",
            "{'epoch': 1, 'batch': 31, 'loss': 6.6575608253479}\n",
            "{'epoch': 1, 'batch': 32, 'loss': 6.797067165374756}\n",
            "{'epoch': 1, 'batch': 33, 'loss': 6.985856056213379}\n",
            "{'epoch': 1, 'batch': 34, 'loss': 6.93283224105835}\n",
            "{'epoch': 1, 'batch': 35, 'loss': 7.23053503036499}\n",
            "{'epoch': 1, 'batch': 36, 'loss': 7.142951011657715}\n",
            "{'epoch': 1, 'batch': 37, 'loss': 6.936826229095459}\n",
            "{'epoch': 1, 'batch': 38, 'loss': 7.2428083419799805}\n",
            "{'epoch': 1, 'batch': 39, 'loss': 7.079965591430664}\n",
            "{'epoch': 1, 'batch': 40, 'loss': 7.308077335357666}\n",
            "{'epoch': 1, 'batch': 41, 'loss': 7.01363468170166}\n",
            "{'epoch': 1, 'batch': 42, 'loss': 7.265499114990234}\n",
            "{'epoch': 1, 'batch': 43, 'loss': 7.0044708251953125}\n",
            "{'epoch': 1, 'batch': 44, 'loss': 6.905257701873779}\n",
            "{'epoch': 1, 'batch': 45, 'loss': 7.067478656768799}\n",
            "{'epoch': 1, 'batch': 46, 'loss': 7.2430806159973145}\n",
            "{'epoch': 1, 'batch': 47, 'loss': 7.500283718109131}\n",
            "{'epoch': 1, 'batch': 48, 'loss': 6.978455543518066}\n",
            "{'epoch': 1, 'batch': 49, 'loss': 7.220013618469238}\n",
            "{'epoch': 1, 'batch': 50, 'loss': 7.414556503295898}\n",
            "{'epoch': 1, 'batch': 51, 'loss': 7.2372260093688965}\n",
            "{'epoch': 1, 'batch': 52, 'loss': 6.862448692321777}\n",
            "{'epoch': 1, 'batch': 53, 'loss': 7.128750801086426}\n",
            "{'epoch': 1, 'batch': 54, 'loss': 7.040372848510742}\n",
            "{'epoch': 1, 'batch': 55, 'loss': 7.085085391998291}\n",
            "{'epoch': 1, 'batch': 56, 'loss': 7.152232646942139}\n",
            "{'epoch': 1, 'batch': 57, 'loss': 7.136503219604492}\n",
            "{'epoch': 1, 'batch': 58, 'loss': 7.103425025939941}\n",
            "{'epoch': 1, 'batch': 59, 'loss': 7.121743202209473}\n",
            "{'epoch': 1, 'batch': 60, 'loss': 7.047360420227051}\n",
            "{'epoch': 1, 'batch': 61, 'loss': 7.202302932739258}\n",
            "{'epoch': 1, 'batch': 62, 'loss': 7.195524215698242}\n",
            "{'epoch': 1, 'batch': 63, 'loss': 7.116426944732666}\n",
            "{'epoch': 1, 'batch': 64, 'loss': 7.220397472381592}\n",
            "{'epoch': 1, 'batch': 65, 'loss': 7.138931751251221}\n",
            "{'epoch': 1, 'batch': 66, 'loss': 7.135562896728516}\n",
            "{'epoch': 1, 'batch': 67, 'loss': 6.95059061050415}\n",
            "{'epoch': 1, 'batch': 68, 'loss': 7.158055305480957}\n",
            "{'epoch': 1, 'batch': 69, 'loss': 6.909990310668945}\n",
            "{'epoch': 1, 'batch': 70, 'loss': 7.330698490142822}\n",
            "{'epoch': 1, 'batch': 71, 'loss': 7.271104335784912}\n",
            "{'epoch': 1, 'batch': 72, 'loss': 7.186607837677002}\n",
            "{'epoch': 1, 'batch': 73, 'loss': 7.2599687576293945}\n",
            "{'epoch': 1, 'batch': 74, 'loss': 7.255630016326904}\n",
            "{'epoch': 1, 'batch': 75, 'loss': 7.392665386199951}\n",
            "{'epoch': 1, 'batch': 76, 'loss': 7.177282333374023}\n",
            "{'epoch': 1, 'batch': 77, 'loss': 7.438004016876221}\n",
            "{'epoch': 1, 'batch': 78, 'loss': 7.554421424865723}\n",
            "{'epoch': 1, 'batch': 79, 'loss': 6.842072010040283}\n",
            "{'epoch': 1, 'batch': 80, 'loss': 7.126998424530029}\n",
            "{'epoch': 1, 'batch': 81, 'loss': 7.29786491394043}\n",
            "{'epoch': 1, 'batch': 82, 'loss': 7.306875705718994}\n",
            "{'epoch': 1, 'batch': 83, 'loss': 7.362139701843262}\n",
            "{'epoch': 1, 'batch': 84, 'loss': 7.164944171905518}\n",
            "{'epoch': 1, 'batch': 85, 'loss': 7.343935966491699}\n",
            "{'epoch': 1, 'batch': 86, 'loss': 7.100757122039795}\n",
            "{'epoch': 1, 'batch': 87, 'loss': 7.2035322189331055}\n",
            "{'epoch': 1, 'batch': 88, 'loss': 7.119540214538574}\n",
            "{'epoch': 1, 'batch': 89, 'loss': 7.226551055908203}\n",
            "{'epoch': 1, 'batch': 90, 'loss': 7.589694499969482}\n",
            "{'epoch': 1, 'batch': 91, 'loss': 7.077204704284668}\n",
            "{'epoch': 1, 'batch': 92, 'loss': 7.3059916496276855}\n",
            "{'epoch': 1, 'batch': 93, 'loss': 6.897592067718506}\n",
            "{'epoch': 2, 'batch': 0, 'loss': 7.089411735534668}\n",
            "{'epoch': 2, 'batch': 1, 'loss': 7.093162536621094}\n",
            "{'epoch': 2, 'batch': 2, 'loss': 7.026339530944824}\n",
            "{'epoch': 2, 'batch': 3, 'loss': 7.254119396209717}\n",
            "{'epoch': 2, 'batch': 4, 'loss': 7.203670501708984}\n",
            "{'epoch': 2, 'batch': 5, 'loss': 7.198747158050537}\n",
            "{'epoch': 2, 'batch': 6, 'loss': 7.585444450378418}\n",
            "{'epoch': 2, 'batch': 7, 'loss': 7.400175094604492}\n",
            "{'epoch': 2, 'batch': 8, 'loss': 7.323892593383789}\n",
            "{'epoch': 2, 'batch': 9, 'loss': 7.174426555633545}\n",
            "{'epoch': 2, 'batch': 10, 'loss': 7.139321804046631}\n",
            "{'epoch': 2, 'batch': 11, 'loss': 7.076294422149658}\n",
            "{'epoch': 2, 'batch': 12, 'loss': 7.154234409332275}\n",
            "{'epoch': 2, 'batch': 13, 'loss': 7.231651782989502}\n",
            "{'epoch': 2, 'batch': 14, 'loss': 6.911143779754639}\n",
            "{'epoch': 2, 'batch': 15, 'loss': 7.012955665588379}\n",
            "{'epoch': 2, 'batch': 16, 'loss': 6.7943220138549805}\n",
            "{'epoch': 2, 'batch': 17, 'loss': 7.007122993469238}\n",
            "{'epoch': 2, 'batch': 18, 'loss': 6.907921314239502}\n",
            "{'epoch': 2, 'batch': 19, 'loss': 7.0164313316345215}\n",
            "{'epoch': 2, 'batch': 20, 'loss': 6.750677108764648}\n",
            "{'epoch': 2, 'batch': 21, 'loss': 7.131309986114502}\n",
            "{'epoch': 2, 'batch': 22, 'loss': 7.087469577789307}\n",
            "{'epoch': 2, 'batch': 23, 'loss': 7.177278995513916}\n",
            "{'epoch': 2, 'batch': 24, 'loss': 7.153909683227539}\n",
            "{'epoch': 2, 'batch': 25, 'loss': 6.886634826660156}\n",
            "{'epoch': 2, 'batch': 26, 'loss': 6.8806281089782715}\n",
            "{'epoch': 2, 'batch': 27, 'loss': 6.878224849700928}\n",
            "{'epoch': 2, 'batch': 28, 'loss': 7.268752098083496}\n",
            "{'epoch': 2, 'batch': 29, 'loss': 7.379044532775879}\n",
            "{'epoch': 2, 'batch': 30, 'loss': 6.735878944396973}\n",
            "{'epoch': 2, 'batch': 31, 'loss': 6.691136360168457}\n",
            "{'epoch': 2, 'batch': 32, 'loss': 6.833725452423096}\n",
            "{'epoch': 2, 'batch': 33, 'loss': 7.019098281860352}\n",
            "{'epoch': 2, 'batch': 34, 'loss': 6.951203346252441}\n",
            "{'epoch': 2, 'batch': 35, 'loss': 7.2512288093566895}\n",
            "{'epoch': 2, 'batch': 36, 'loss': 7.145938873291016}\n",
            "{'epoch': 2, 'batch': 37, 'loss': 6.936655521392822}\n",
            "{'epoch': 2, 'batch': 38, 'loss': 7.261096954345703}\n",
            "{'epoch': 2, 'batch': 39, 'loss': 7.083192825317383}\n",
            "{'epoch': 2, 'batch': 40, 'loss': 7.314365863800049}\n",
            "{'epoch': 2, 'batch': 41, 'loss': 7.015402317047119}\n",
            "{'epoch': 2, 'batch': 42, 'loss': 7.264835834503174}\n",
            "{'epoch': 2, 'batch': 43, 'loss': 6.986181735992432}\n",
            "{'epoch': 2, 'batch': 44, 'loss': 6.890961170196533}\n",
            "{'epoch': 2, 'batch': 45, 'loss': 7.025659084320068}\n",
            "{'epoch': 2, 'batch': 46, 'loss': 7.218501091003418}\n",
            "{'epoch': 2, 'batch': 47, 'loss': 7.487802505493164}\n",
            "{'epoch': 2, 'batch': 48, 'loss': 6.953025817871094}\n",
            "{'epoch': 2, 'batch': 49, 'loss': 7.192749977111816}\n",
            "{'epoch': 2, 'batch': 50, 'loss': 7.375744819641113}\n",
            "{'epoch': 2, 'batch': 51, 'loss': 7.20834493637085}\n",
            "{'epoch': 2, 'batch': 52, 'loss': 6.835087776184082}\n",
            "{'epoch': 2, 'batch': 53, 'loss': 7.096706390380859}\n",
            "{'epoch': 2, 'batch': 54, 'loss': 6.999605178833008}\n",
            "{'epoch': 2, 'batch': 55, 'loss': 7.030905723571777}\n",
            "{'epoch': 2, 'batch': 56, 'loss': 7.103786468505859}\n",
            "{'epoch': 2, 'batch': 57, 'loss': 7.066884517669678}\n",
            "{'epoch': 2, 'batch': 58, 'loss': 7.0362138748168945}\n",
            "{'epoch': 2, 'batch': 59, 'loss': 7.068305015563965}\n",
            "{'epoch': 2, 'batch': 60, 'loss': 6.992506504058838}\n",
            "{'epoch': 2, 'batch': 61, 'loss': 7.1455841064453125}\n",
            "{'epoch': 2, 'batch': 62, 'loss': 7.137747287750244}\n",
            "{'epoch': 2, 'batch': 63, 'loss': 7.054628849029541}\n",
            "{'epoch': 2, 'batch': 64, 'loss': 7.1603827476501465}\n",
            "{'epoch': 2, 'batch': 65, 'loss': 7.070152282714844}\n",
            "{'epoch': 2, 'batch': 66, 'loss': 7.069371700286865}\n",
            "{'epoch': 2, 'batch': 67, 'loss': 6.884700775146484}\n",
            "{'epoch': 2, 'batch': 68, 'loss': 7.080389499664307}\n",
            "{'epoch': 2, 'batch': 69, 'loss': 6.839477062225342}\n",
            "{'epoch': 2, 'batch': 70, 'loss': 7.249464988708496}\n",
            "{'epoch': 2, 'batch': 71, 'loss': 7.187577247619629}\n",
            "{'epoch': 2, 'batch': 72, 'loss': 7.106334686279297}\n",
            "{'epoch': 2, 'batch': 73, 'loss': 7.154041290283203}\n",
            "{'epoch': 2, 'batch': 74, 'loss': 7.16018533706665}\n",
            "{'epoch': 2, 'batch': 75, 'loss': 7.280594825744629}\n",
            "{'epoch': 2, 'batch': 76, 'loss': 7.076740741729736}\n",
            "{'epoch': 2, 'batch': 77, 'loss': 7.336731910705566}\n",
            "{'epoch': 2, 'batch': 78, 'loss': 7.421682834625244}\n",
            "{'epoch': 2, 'batch': 79, 'loss': 6.76716423034668}\n",
            "{'epoch': 2, 'batch': 80, 'loss': 7.011374473571777}\n",
            "{'epoch': 2, 'batch': 81, 'loss': 7.18914270401001}\n",
            "{'epoch': 2, 'batch': 82, 'loss': 7.1842217445373535}\n",
            "{'epoch': 2, 'batch': 83, 'loss': 7.261905193328857}\n",
            "{'epoch': 2, 'batch': 84, 'loss': 7.055435657501221}\n",
            "{'epoch': 2, 'batch': 85, 'loss': 7.256287574768066}\n",
            "{'epoch': 2, 'batch': 86, 'loss': 6.991283416748047}\n",
            "{'epoch': 2, 'batch': 87, 'loss': 7.093146800994873}\n",
            "{'epoch': 2, 'batch': 88, 'loss': 6.986490726470947}\n",
            "{'epoch': 2, 'batch': 89, 'loss': 7.095125675201416}\n",
            "{'epoch': 2, 'batch': 90, 'loss': 7.463139533996582}\n",
            "{'epoch': 2, 'batch': 91, 'loss': 6.955280303955078}\n",
            "{'epoch': 2, 'batch': 92, 'loss': 7.193880081176758}\n",
            "{'epoch': 2, 'batch': 93, 'loss': 6.689777374267578}\n",
            "{'epoch': 3, 'batch': 0, 'loss': 7.0316267013549805}\n",
            "{'epoch': 3, 'batch': 1, 'loss': 6.986539363861084}\n",
            "{'epoch': 3, 'batch': 2, 'loss': 6.915770530700684}\n",
            "{'epoch': 3, 'batch': 3, 'loss': 7.158056735992432}\n",
            "{'epoch': 3, 'batch': 4, 'loss': 7.0769124031066895}\n",
            "{'epoch': 3, 'batch': 5, 'loss': 7.062004089355469}\n",
            "{'epoch': 3, 'batch': 6, 'loss': 7.504307270050049}\n",
            "{'epoch': 3, 'batch': 7, 'loss': 7.294898509979248}\n",
            "{'epoch': 3, 'batch': 8, 'loss': 7.22425651550293}\n",
            "{'epoch': 3, 'batch': 9, 'loss': 7.1648359298706055}\n",
            "{'epoch': 3, 'batch': 10, 'loss': 7.163311958312988}\n",
            "{'epoch': 3, 'batch': 11, 'loss': 7.047404766082764}\n",
            "{'epoch': 3, 'batch': 12, 'loss': 7.113534450531006}\n",
            "{'epoch': 3, 'batch': 13, 'loss': 7.215923309326172}\n",
            "{'epoch': 3, 'batch': 14, 'loss': 6.8613104820251465}\n",
            "{'epoch': 3, 'batch': 15, 'loss': 6.976993083953857}\n",
            "{'epoch': 3, 'batch': 16, 'loss': 6.7255377769470215}\n",
            "{'epoch': 3, 'batch': 17, 'loss': 6.964001178741455}\n",
            "{'epoch': 3, 'batch': 18, 'loss': 6.843975067138672}\n",
            "{'epoch': 3, 'batch': 19, 'loss': 6.944701194763184}\n",
            "{'epoch': 3, 'batch': 20, 'loss': 6.6550068855285645}\n",
            "{'epoch': 3, 'batch': 21, 'loss': 7.092876434326172}\n",
            "{'epoch': 3, 'batch': 22, 'loss': 7.048202991485596}\n",
            "{'epoch': 3, 'batch': 23, 'loss': 7.128530502319336}\n",
            "{'epoch': 3, 'batch': 24, 'loss': 7.093688488006592}\n",
            "{'epoch': 3, 'batch': 25, 'loss': 6.825223922729492}\n",
            "{'epoch': 3, 'batch': 26, 'loss': 6.797015190124512}\n",
            "{'epoch': 3, 'batch': 27, 'loss': 6.792540073394775}\n",
            "{'epoch': 3, 'batch': 28, 'loss': 7.191120624542236}\n",
            "{'epoch': 3, 'batch': 29, 'loss': 7.308274745941162}\n",
            "{'epoch': 3, 'batch': 30, 'loss': 6.639799118041992}\n",
            "{'epoch': 3, 'batch': 31, 'loss': 6.576381206512451}\n",
            "{'epoch': 3, 'batch': 32, 'loss': 6.7052903175354}\n",
            "{'epoch': 3, 'batch': 33, 'loss': 6.925488471984863}\n",
            "{'epoch': 3, 'batch': 34, 'loss': 6.8792548179626465}\n",
            "{'epoch': 3, 'batch': 35, 'loss': 7.133419990539551}\n",
            "{'epoch': 3, 'batch': 36, 'loss': 7.02562952041626}\n",
            "{'epoch': 3, 'batch': 37, 'loss': 6.797260284423828}\n",
            "{'epoch': 3, 'batch': 38, 'loss': 7.158056735992432}\n",
            "{'epoch': 3, 'batch': 39, 'loss': 6.961558818817139}\n",
            "{'epoch': 3, 'batch': 40, 'loss': 7.188659191131592}\n",
            "{'epoch': 3, 'batch': 41, 'loss': 6.844229698181152}\n",
            "{'epoch': 3, 'batch': 42, 'loss': 7.1131744384765625}\n",
            "{'epoch': 3, 'batch': 43, 'loss': 6.865514278411865}\n",
            "{'epoch': 3, 'batch': 44, 'loss': 6.788662910461426}\n",
            "{'epoch': 3, 'batch': 45, 'loss': 6.887295246124268}\n",
            "{'epoch': 3, 'batch': 46, 'loss': 7.067434787750244}\n",
            "{'epoch': 3, 'batch': 47, 'loss': 7.406147480010986}\n",
            "{'epoch': 3, 'batch': 48, 'loss': 6.737293243408203}\n",
            "{'epoch': 3, 'batch': 49, 'loss': 7.106809616088867}\n",
            "{'epoch': 3, 'batch': 50, 'loss': 7.208202362060547}\n",
            "{'epoch': 3, 'batch': 51, 'loss': 7.129446029663086}\n",
            "{'epoch': 3, 'batch': 52, 'loss': 6.635274887084961}\n",
            "{'epoch': 3, 'batch': 53, 'loss': 6.983967304229736}\n",
            "{'epoch': 3, 'batch': 54, 'loss': 6.840747833251953}\n",
            "{'epoch': 3, 'batch': 55, 'loss': 6.856298446655273}\n",
            "{'epoch': 3, 'batch': 56, 'loss': 6.970161437988281}\n",
            "{'epoch': 3, 'batch': 57, 'loss': 6.900485038757324}\n",
            "{'epoch': 3, 'batch': 58, 'loss': 6.842823028564453}\n",
            "{'epoch': 3, 'batch': 59, 'loss': 6.9494757652282715}\n",
            "{'epoch': 3, 'batch': 60, 'loss': 6.8059587478637695}\n",
            "{'epoch': 3, 'batch': 61, 'loss': 7.005537509918213}\n",
            "{'epoch': 3, 'batch': 62, 'loss': 6.988588333129883}\n",
            "{'epoch': 3, 'batch': 63, 'loss': 6.888298511505127}\n",
            "{'epoch': 3, 'batch': 64, 'loss': 6.965331077575684}\n",
            "{'epoch': 3, 'batch': 65, 'loss': 6.90358829498291}\n",
            "{'epoch': 3, 'batch': 66, 'loss': 6.90347957611084}\n",
            "{'epoch': 3, 'batch': 67, 'loss': 6.719103813171387}\n",
            "{'epoch': 3, 'batch': 68, 'loss': 6.917199611663818}\n",
            "{'epoch': 3, 'batch': 69, 'loss': 6.641750812530518}\n",
            "{'epoch': 3, 'batch': 70, 'loss': 7.14058256149292}\n",
            "{'epoch': 3, 'batch': 71, 'loss': 7.024377822875977}\n",
            "{'epoch': 3, 'batch': 72, 'loss': 6.945758819580078}\n",
            "{'epoch': 3, 'batch': 73, 'loss': 6.9487152099609375}\n",
            "{'epoch': 3, 'batch': 74, 'loss': 6.999006271362305}\n",
            "{'epoch': 3, 'batch': 75, 'loss': 7.074614524841309}\n",
            "{'epoch': 3, 'batch': 76, 'loss': 6.891122817993164}\n",
            "{'epoch': 3, 'batch': 77, 'loss': 7.212437152862549}\n",
            "{'epoch': 3, 'batch': 78, 'loss': 7.213535308837891}\n",
            "{'epoch': 3, 'batch': 79, 'loss': 6.615224838256836}\n",
            "{'epoch': 3, 'batch': 80, 'loss': 6.782075881958008}\n",
            "{'epoch': 3, 'batch': 81, 'loss': 7.021529197692871}\n",
            "{'epoch': 3, 'batch': 82, 'loss': 6.985543727874756}\n",
            "{'epoch': 3, 'batch': 83, 'loss': 7.077090740203857}\n",
            "{'epoch': 3, 'batch': 84, 'loss': 6.91580057144165}\n",
            "{'epoch': 3, 'batch': 85, 'loss': 7.090559959411621}\n",
            "{'epoch': 3, 'batch': 86, 'loss': 6.80530309677124}\n",
            "{'epoch': 3, 'batch': 87, 'loss': 6.902678489685059}\n",
            "{'epoch': 3, 'batch': 88, 'loss': 6.7759833335876465}\n",
            "{'epoch': 3, 'batch': 89, 'loss': 6.8795647621154785}\n",
            "{'epoch': 3, 'batch': 90, 'loss': 7.311097145080566}\n",
            "{'epoch': 3, 'batch': 91, 'loss': 6.778155326843262}\n",
            "{'epoch': 3, 'batch': 92, 'loss': 7.041069507598877}\n",
            "{'epoch': 3, 'batch': 93, 'loss': 6.447866916656494}\n",
            "{'epoch': 4, 'batch': 0, 'loss': 6.850339412689209}\n",
            "{'epoch': 4, 'batch': 1, 'loss': 6.810286521911621}\n",
            "{'epoch': 4, 'batch': 2, 'loss': 6.760937213897705}\n",
            "{'epoch': 4, 'batch': 3, 'loss': 7.000776767730713}\n",
            "{'epoch': 4, 'batch': 4, 'loss': 6.882236003875732}\n",
            "{'epoch': 4, 'batch': 5, 'loss': 6.882316589355469}\n",
            "{'epoch': 4, 'batch': 6, 'loss': 7.37379264831543}\n",
            "{'epoch': 4, 'batch': 7, 'loss': 7.133635520935059}\n",
            "{'epoch': 4, 'batch': 8, 'loss': 7.041618824005127}\n",
            "{'epoch': 4, 'batch': 9, 'loss': 7.010616779327393}\n",
            "{'epoch': 4, 'batch': 10, 'loss': 7.033181190490723}\n",
            "{'epoch': 4, 'batch': 11, 'loss': 6.905210018157959}\n",
            "{'epoch': 4, 'batch': 12, 'loss': 6.988474369049072}\n",
            "{'epoch': 4, 'batch': 13, 'loss': 7.086032390594482}\n",
            "{'epoch': 4, 'batch': 14, 'loss': 6.709656238555908}\n",
            "{'epoch': 4, 'batch': 15, 'loss': 6.861270904541016}\n",
            "{'epoch': 4, 'batch': 16, 'loss': 6.593158721923828}\n",
            "{'epoch': 4, 'batch': 17, 'loss': 6.826464653015137}\n",
            "{'epoch': 4, 'batch': 18, 'loss': 6.695293426513672}\n",
            "{'epoch': 4, 'batch': 19, 'loss': 6.826999664306641}\n",
            "{'epoch': 4, 'batch': 20, 'loss': 6.503383636474609}\n",
            "{'epoch': 4, 'batch': 21, 'loss': 6.995532512664795}\n",
            "{'epoch': 4, 'batch': 22, 'loss': 6.960890293121338}\n",
            "{'epoch': 4, 'batch': 23, 'loss': 7.03394889831543}\n",
            "{'epoch': 4, 'batch': 24, 'loss': 7.01888370513916}\n",
            "{'epoch': 4, 'batch': 25, 'loss': 6.721045970916748}\n",
            "{'epoch': 4, 'batch': 26, 'loss': 6.625279903411865}\n",
            "{'epoch': 4, 'batch': 27, 'loss': 6.660151958465576}\n",
            "{'epoch': 4, 'batch': 28, 'loss': 7.1191487312316895}\n",
            "{'epoch': 4, 'batch': 29, 'loss': 7.207676887512207}\n",
            "{'epoch': 4, 'batch': 30, 'loss': 6.529998779296875}\n",
            "{'epoch': 4, 'batch': 31, 'loss': 6.446447372436523}\n",
            "{'epoch': 4, 'batch': 32, 'loss': 6.565306186676025}\n",
            "{'epoch': 4, 'batch': 33, 'loss': 6.816249847412109}\n",
            "{'epoch': 4, 'batch': 34, 'loss': 6.788836479187012}\n",
            "{'epoch': 4, 'batch': 35, 'loss': 6.988410949707031}\n",
            "{'epoch': 4, 'batch': 36, 'loss': 6.894834041595459}\n",
            "{'epoch': 4, 'batch': 37, 'loss': 6.703588485717773}\n",
            "{'epoch': 4, 'batch': 38, 'loss': 7.079992771148682}\n",
            "{'epoch': 4, 'batch': 39, 'loss': 6.860605239868164}\n",
            "{'epoch': 4, 'batch': 40, 'loss': 7.075542449951172}\n",
            "{'epoch': 4, 'batch': 41, 'loss': 6.697412490844727}\n",
            "{'epoch': 4, 'batch': 42, 'loss': 7.015875339508057}\n",
            "{'epoch': 4, 'batch': 43, 'loss': 6.736297607421875}\n",
            "{'epoch': 4, 'batch': 44, 'loss': 6.67979097366333}\n",
            "{'epoch': 4, 'batch': 45, 'loss': 6.777166843414307}\n",
            "{'epoch': 4, 'batch': 46, 'loss': 6.960599899291992}\n",
            "{'epoch': 4, 'batch': 47, 'loss': 7.288760662078857}\n",
            "{'epoch': 4, 'batch': 48, 'loss': 6.587948322296143}\n",
            "{'epoch': 4, 'batch': 49, 'loss': 6.979323387145996}\n",
            "{'epoch': 4, 'batch': 50, 'loss': 7.084733963012695}\n",
            "{'epoch': 4, 'batch': 51, 'loss': 7.036910057067871}\n",
            "{'epoch': 4, 'batch': 52, 'loss': 6.4926066398620605}\n",
            "{'epoch': 4, 'batch': 53, 'loss': 6.8831329345703125}\n",
            "{'epoch': 4, 'batch': 54, 'loss': 6.711977958679199}\n",
            "{'epoch': 4, 'batch': 55, 'loss': 6.72821569442749}\n",
            "{'epoch': 4, 'batch': 56, 'loss': 6.822200775146484}\n",
            "{'epoch': 4, 'batch': 57, 'loss': 6.727891445159912}\n",
            "{'epoch': 4, 'batch': 58, 'loss': 6.680116653442383}\n",
            "{'epoch': 4, 'batch': 59, 'loss': 6.805516242980957}\n",
            "{'epoch': 4, 'batch': 60, 'loss': 6.687580585479736}\n",
            "{'epoch': 4, 'batch': 61, 'loss': 6.845154762268066}\n",
            "{'epoch': 4, 'batch': 62, 'loss': 6.861425399780273}\n",
            "{'epoch': 4, 'batch': 63, 'loss': 6.742166996002197}\n",
            "{'epoch': 4, 'batch': 64, 'loss': 6.777204990386963}\n",
            "{'epoch': 4, 'batch': 65, 'loss': 6.76741886138916}\n",
            "{'epoch': 4, 'batch': 66, 'loss': 6.767059803009033}\n",
            "{'epoch': 4, 'batch': 67, 'loss': 6.551295280456543}\n",
            "{'epoch': 4, 'batch': 68, 'loss': 6.760944843292236}\n",
            "{'epoch': 4, 'batch': 69, 'loss': 6.454268932342529}\n",
            "{'epoch': 4, 'batch': 70, 'loss': 7.02996301651001}\n",
            "{'epoch': 4, 'batch': 71, 'loss': 6.876271724700928}\n",
            "{'epoch': 4, 'batch': 72, 'loss': 6.8017802238464355}\n",
            "{'epoch': 4, 'batch': 73, 'loss': 6.804946422576904}\n",
            "{'epoch': 4, 'batch': 74, 'loss': 6.8474626541137695}\n",
            "{'epoch': 4, 'batch': 75, 'loss': 6.919066429138184}\n",
            "{'epoch': 4, 'batch': 76, 'loss': 6.753147602081299}\n",
            "{'epoch': 4, 'batch': 77, 'loss': 7.097543716430664}\n",
            "{'epoch': 4, 'batch': 78, 'loss': 7.073156356811523}\n",
            "{'epoch': 4, 'batch': 79, 'loss': 6.500195503234863}\n",
            "{'epoch': 4, 'batch': 80, 'loss': 6.634359836578369}\n",
            "{'epoch': 4, 'batch': 81, 'loss': 6.897670269012451}\n",
            "{'epoch': 4, 'batch': 82, 'loss': 6.850762844085693}\n",
            "{'epoch': 4, 'batch': 83, 'loss': 6.961362838745117}\n",
            "{'epoch': 4, 'batch': 84, 'loss': 6.825952529907227}\n",
            "{'epoch': 4, 'batch': 85, 'loss': 6.963428497314453}\n",
            "{'epoch': 4, 'batch': 86, 'loss': 6.668655872344971}\n",
            "{'epoch': 4, 'batch': 87, 'loss': 6.758615970611572}\n",
            "{'epoch': 4, 'batch': 88, 'loss': 6.621159553527832}\n",
            "{'epoch': 4, 'batch': 89, 'loss': 6.7538228034973145}\n",
            "{'epoch': 4, 'batch': 90, 'loss': 7.222804069519043}\n",
            "{'epoch': 4, 'batch': 91, 'loss': 6.6391425132751465}\n",
            "{'epoch': 4, 'batch': 92, 'loss': 6.895749568939209}\n",
            "{'epoch': 4, 'batch': 93, 'loss': 6.257340908050537}\n",
            "{'epoch': 5, 'batch': 0, 'loss': 6.73256254196167}\n",
            "{'epoch': 5, 'batch': 1, 'loss': 6.676562309265137}\n",
            "{'epoch': 5, 'batch': 2, 'loss': 6.635880470275879}\n",
            "{'epoch': 5, 'batch': 3, 'loss': 6.846588134765625}\n",
            "{'epoch': 5, 'batch': 4, 'loss': 6.732475757598877}\n",
            "{'epoch': 5, 'batch': 5, 'loss': 6.74508810043335}\n",
            "{'epoch': 5, 'batch': 6, 'loss': 7.270211696624756}\n",
            "{'epoch': 5, 'batch': 7, 'loss': 7.024907112121582}\n",
            "{'epoch': 5, 'batch': 8, 'loss': 6.919956684112549}\n",
            "{'epoch': 5, 'batch': 9, 'loss': 6.9030327796936035}\n",
            "{'epoch': 5, 'batch': 10, 'loss': 6.939428806304932}\n",
            "{'epoch': 5, 'batch': 11, 'loss': 6.761228561401367}\n",
            "{'epoch': 5, 'batch': 12, 'loss': 6.879323482513428}\n",
            "{'epoch': 5, 'batch': 13, 'loss': 6.995640277862549}\n",
            "{'epoch': 5, 'batch': 14, 'loss': 6.592513561248779}\n",
            "{'epoch': 5, 'batch': 15, 'loss': 6.762656211853027}\n",
            "{'epoch': 5, 'batch': 16, 'loss': 6.486164569854736}\n",
            "{'epoch': 5, 'batch': 17, 'loss': 6.715425491333008}\n",
            "{'epoch': 5, 'batch': 18, 'loss': 6.559777736663818}\n",
            "{'epoch': 5, 'batch': 19, 'loss': 6.7098283767700195}\n",
            "{'epoch': 5, 'batch': 20, 'loss': 6.37142276763916}\n",
            "{'epoch': 5, 'batch': 21, 'loss': 6.883807182312012}\n",
            "{'epoch': 5, 'batch': 22, 'loss': 6.874110221862793}\n",
            "{'epoch': 5, 'batch': 23, 'loss': 6.93081521987915}\n",
            "{'epoch': 5, 'batch': 24, 'loss': 6.929941654205322}\n",
            "{'epoch': 5, 'batch': 25, 'loss': 6.62178373336792}\n",
            "{'epoch': 5, 'batch': 26, 'loss': 6.456557750701904}\n",
            "{'epoch': 5, 'batch': 27, 'loss': 6.540116786956787}\n",
            "{'epoch': 5, 'batch': 28, 'loss': 7.034323215484619}\n",
            "{'epoch': 5, 'batch': 29, 'loss': 7.090885639190674}\n",
            "{'epoch': 5, 'batch': 30, 'loss': 6.40208101272583}\n",
            "{'epoch': 5, 'batch': 31, 'loss': 6.314365863800049}\n",
            "{'epoch': 5, 'batch': 32, 'loss': 6.459732532501221}\n",
            "{'epoch': 5, 'batch': 33, 'loss': 6.697620391845703}\n",
            "{'epoch': 5, 'batch': 34, 'loss': 6.6486592292785645}\n",
            "{'epoch': 5, 'batch': 35, 'loss': 6.839498043060303}\n",
            "{'epoch': 5, 'batch': 36, 'loss': 6.743853569030762}\n",
            "{'epoch': 5, 'batch': 37, 'loss': 6.567586898803711}\n",
            "{'epoch': 5, 'batch': 38, 'loss': 6.993706226348877}\n",
            "{'epoch': 5, 'batch': 39, 'loss': 6.742607116699219}\n",
            "{'epoch': 5, 'batch': 40, 'loss': 6.940690994262695}\n",
            "{'epoch': 5, 'batch': 41, 'loss': 6.557438373565674}\n",
            "{'epoch': 5, 'batch': 42, 'loss': 6.9164605140686035}\n",
            "{'epoch': 5, 'batch': 43, 'loss': 6.611199378967285}\n",
            "{'epoch': 5, 'batch': 44, 'loss': 6.549371242523193}\n",
            "{'epoch': 5, 'batch': 45, 'loss': 6.662115097045898}\n",
            "{'epoch': 5, 'batch': 46, 'loss': 6.851545333862305}\n",
            "{'epoch': 5, 'batch': 47, 'loss': 7.181427001953125}\n",
            "{'epoch': 5, 'batch': 48, 'loss': 6.4499077796936035}\n",
            "{'epoch': 5, 'batch': 49, 'loss': 6.877131938934326}\n",
            "{'epoch': 5, 'batch': 50, 'loss': 6.964049816131592}\n",
            "{'epoch': 5, 'batch': 51, 'loss': 6.937211036682129}\n",
            "{'epoch': 5, 'batch': 52, 'loss': 6.322338104248047}\n",
            "{'epoch': 5, 'batch': 53, 'loss': 6.7352681159973145}\n",
            "{'epoch': 5, 'batch': 54, 'loss': 6.5866265296936035}\n",
            "{'epoch': 5, 'batch': 55, 'loss': 6.590319633483887}\n",
            "{'epoch': 5, 'batch': 56, 'loss': 6.68403959274292}\n",
            "{'epoch': 5, 'batch': 57, 'loss': 6.58954381942749}\n",
            "{'epoch': 5, 'batch': 58, 'loss': 6.538150787353516}\n",
            "{'epoch': 5, 'batch': 59, 'loss': 6.672939300537109}\n",
            "{'epoch': 5, 'batch': 60, 'loss': 6.545780658721924}\n",
            "{'epoch': 5, 'batch': 61, 'loss': 6.696630001068115}\n",
            "{'epoch': 5, 'batch': 62, 'loss': 6.72330904006958}\n",
            "{'epoch': 5, 'batch': 63, 'loss': 6.58289098739624}\n",
            "{'epoch': 5, 'batch': 64, 'loss': 6.602564811706543}\n",
            "{'epoch': 5, 'batch': 65, 'loss': 6.623159408569336}\n",
            "{'epoch': 5, 'batch': 66, 'loss': 6.630208969116211}\n",
            "{'epoch': 5, 'batch': 67, 'loss': 6.373071670532227}\n",
            "{'epoch': 5, 'batch': 68, 'loss': 6.589938640594482}\n",
            "{'epoch': 5, 'batch': 69, 'loss': 6.266027927398682}\n",
            "{'epoch': 5, 'batch': 70, 'loss': 6.891443252563477}\n",
            "{'epoch': 5, 'batch': 71, 'loss': 6.720127105712891}\n",
            "{'epoch': 5, 'batch': 72, 'loss': 6.607961654663086}\n",
            "{'epoch': 5, 'batch': 73, 'loss': 6.61907958984375}\n",
            "{'epoch': 5, 'batch': 74, 'loss': 6.674008369445801}\n",
            "{'epoch': 5, 'batch': 75, 'loss': 6.763482093811035}\n",
            "{'epoch': 5, 'batch': 76, 'loss': 6.59438943862915}\n",
            "{'epoch': 5, 'batch': 77, 'loss': 6.9204888343811035}\n",
            "{'epoch': 5, 'batch': 78, 'loss': 6.8865065574646}\n",
            "{'epoch': 5, 'batch': 79, 'loss': 6.293558597564697}\n",
            "{'epoch': 5, 'batch': 80, 'loss': 6.448809623718262}\n",
            "{'epoch': 5, 'batch': 81, 'loss': 6.7266764640808105}\n",
            "{'epoch': 5, 'batch': 82, 'loss': 6.686107158660889}\n",
            "{'epoch': 5, 'batch': 83, 'loss': 6.79848051071167}\n",
            "{'epoch': 5, 'batch': 84, 'loss': 6.6707987785339355}\n",
            "{'epoch': 5, 'batch': 85, 'loss': 6.793317794799805}\n",
            "{'epoch': 5, 'batch': 86, 'loss': 6.497702598571777}\n",
            "{'epoch': 5, 'batch': 87, 'loss': 6.592411518096924}\n",
            "{'epoch': 5, 'batch': 88, 'loss': 6.432774066925049}\n",
            "{'epoch': 5, 'batch': 89, 'loss': 6.604489803314209}\n",
            "{'epoch': 5, 'batch': 90, 'loss': 7.088211536407471}\n",
            "{'epoch': 5, 'batch': 91, 'loss': 6.471433639526367}\n",
            "{'epoch': 5, 'batch': 92, 'loss': 6.722938537597656}\n",
            "{'epoch': 5, 'batch': 93, 'loss': 6.064517974853516}\n",
            "{'epoch': 6, 'batch': 0, 'loss': 6.609591007232666}\n",
            "{'epoch': 6, 'batch': 1, 'loss': 6.515091896057129}\n",
            "{'epoch': 6, 'batch': 2, 'loss': 6.494226455688477}\n",
            "{'epoch': 6, 'batch': 3, 'loss': 6.711101531982422}\n",
            "{'epoch': 6, 'batch': 4, 'loss': 6.59257173538208}\n",
            "{'epoch': 6, 'batch': 5, 'loss': 6.589110374450684}\n",
            "{'epoch': 6, 'batch': 6, 'loss': 7.141651153564453}\n",
            "{'epoch': 6, 'batch': 7, 'loss': 6.880714416503906}\n",
            "{'epoch': 6, 'batch': 8, 'loss': 6.786868095397949}\n",
            "{'epoch': 6, 'batch': 9, 'loss': 6.777273178100586}\n",
            "{'epoch': 6, 'batch': 10, 'loss': 6.830947399139404}\n",
            "{'epoch': 6, 'batch': 11, 'loss': 6.601215839385986}\n",
            "{'epoch': 6, 'batch': 12, 'loss': 6.734277725219727}\n",
            "{'epoch': 6, 'batch': 13, 'loss': 6.861557483673096}\n",
            "{'epoch': 6, 'batch': 14, 'loss': 6.445608139038086}\n",
            "{'epoch': 6, 'batch': 15, 'loss': 6.593759059906006}\n",
            "{'epoch': 6, 'batch': 16, 'loss': 6.347766876220703}\n",
            "{'epoch': 6, 'batch': 17, 'loss': 6.560005187988281}\n",
            "{'epoch': 6, 'batch': 18, 'loss': 6.388613700866699}\n",
            "{'epoch': 6, 'batch': 19, 'loss': 6.567215919494629}\n",
            "{'epoch': 6, 'batch': 20, 'loss': 6.193613529205322}\n",
            "{'epoch': 6, 'batch': 21, 'loss': 6.736116886138916}\n",
            "{'epoch': 6, 'batch': 22, 'loss': 6.75873327255249}\n",
            "{'epoch': 6, 'batch': 23, 'loss': 6.809548854827881}\n",
            "{'epoch': 6, 'batch': 24, 'loss': 6.808326244354248}\n",
            "{'epoch': 6, 'batch': 25, 'loss': 6.5003790855407715}\n",
            "{'epoch': 6, 'batch': 26, 'loss': 6.297207832336426}\n",
            "{'epoch': 6, 'batch': 27, 'loss': 6.396762371063232}\n",
            "{'epoch': 6, 'batch': 28, 'loss': 6.9294023513793945}\n",
            "{'epoch': 6, 'batch': 29, 'loss': 6.978758335113525}\n",
            "{'epoch': 6, 'batch': 30, 'loss': 6.228031635284424}\n",
            "{'epoch': 6, 'batch': 31, 'loss': 6.166106224060059}\n",
            "{'epoch': 6, 'batch': 32, 'loss': 6.3273468017578125}\n",
            "{'epoch': 6, 'batch': 33, 'loss': 6.579988479614258}\n",
            "{'epoch': 6, 'batch': 34, 'loss': 6.517008304595947}\n",
            "{'epoch': 6, 'batch': 35, 'loss': 6.688998699188232}\n",
            "{'epoch': 6, 'batch': 36, 'loss': 6.593069553375244}\n",
            "{'epoch': 6, 'batch': 37, 'loss': 6.439306259155273}\n",
            "{'epoch': 6, 'batch': 38, 'loss': 6.876124382019043}\n",
            "{'epoch': 6, 'batch': 39, 'loss': 6.5993971824646}\n",
            "{'epoch': 6, 'batch': 40, 'loss': 6.816308975219727}\n",
            "{'epoch': 6, 'batch': 41, 'loss': 6.39491081237793}\n",
            "{'epoch': 6, 'batch': 42, 'loss': 6.811882972717285}\n",
            "{'epoch': 6, 'batch': 43, 'loss': 6.431095600128174}\n",
            "{'epoch': 6, 'batch': 44, 'loss': 6.387248992919922}\n",
            "{'epoch': 6, 'batch': 45, 'loss': 6.495025634765625}\n",
            "{'epoch': 6, 'batch': 46, 'loss': 6.680950164794922}\n",
            "{'epoch': 6, 'batch': 47, 'loss': 7.021552085876465}\n",
            "{'epoch': 6, 'batch': 48, 'loss': 6.24584436416626}\n",
            "{'epoch': 6, 'batch': 49, 'loss': 6.683479309082031}\n",
            "{'epoch': 6, 'batch': 50, 'loss': 6.790555477142334}\n",
            "{'epoch': 6, 'batch': 51, 'loss': 6.771903991699219}\n",
            "{'epoch': 6, 'batch': 52, 'loss': 6.1273579597473145}\n",
            "{'epoch': 6, 'batch': 53, 'loss': 6.537086009979248}\n",
            "{'epoch': 6, 'batch': 54, 'loss': 6.42055606842041}\n",
            "{'epoch': 6, 'batch': 55, 'loss': 6.392749309539795}\n",
            "{'epoch': 6, 'batch': 56, 'loss': 6.514614105224609}\n",
            "{'epoch': 6, 'batch': 57, 'loss': 6.4274678230285645}\n",
            "{'epoch': 6, 'batch': 58, 'loss': 6.352044582366943}\n",
            "{'epoch': 6, 'batch': 59, 'loss': 6.490749359130859}\n",
            "{'epoch': 6, 'batch': 60, 'loss': 6.413449287414551}\n",
            "{'epoch': 6, 'batch': 61, 'loss': 6.534996032714844}\n",
            "{'epoch': 6, 'batch': 62, 'loss': 6.556417465209961}\n",
            "{'epoch': 6, 'batch': 63, 'loss': 6.4130048751831055}\n",
            "{'epoch': 6, 'batch': 64, 'loss': 6.4359517097473145}\n",
            "{'epoch': 6, 'batch': 65, 'loss': 6.454764366149902}\n",
            "{'epoch': 6, 'batch': 66, 'loss': 6.490885257720947}\n",
            "{'epoch': 6, 'batch': 67, 'loss': 6.206069469451904}\n",
            "{'epoch': 6, 'batch': 68, 'loss': 6.408320426940918}\n",
            "{'epoch': 6, 'batch': 69, 'loss': 6.084135055541992}\n",
            "{'epoch': 6, 'batch': 70, 'loss': 6.710299968719482}\n",
            "{'epoch': 6, 'batch': 71, 'loss': 6.539402484893799}\n",
            "{'epoch': 6, 'batch': 72, 'loss': 6.4395976066589355}\n",
            "{'epoch': 6, 'batch': 73, 'loss': 6.429098129272461}\n",
            "{'epoch': 6, 'batch': 74, 'loss': 6.516283988952637}\n",
            "{'epoch': 6, 'batch': 75, 'loss': 6.584498405456543}\n",
            "{'epoch': 6, 'batch': 76, 'loss': 6.435857772827148}\n",
            "{'epoch': 6, 'batch': 77, 'loss': 6.73146390914917}\n",
            "{'epoch': 6, 'batch': 78, 'loss': 6.696804523468018}\n",
            "{'epoch': 6, 'batch': 79, 'loss': 6.122483253479004}\n",
            "{'epoch': 6, 'batch': 80, 'loss': 6.273152828216553}\n",
            "{'epoch': 6, 'batch': 81, 'loss': 6.531432151794434}\n",
            "{'epoch': 6, 'batch': 82, 'loss': 6.49408483505249}\n",
            "{'epoch': 6, 'batch': 83, 'loss': 6.607076644897461}\n",
            "{'epoch': 6, 'batch': 84, 'loss': 6.5065226554870605}\n",
            "{'epoch': 6, 'batch': 85, 'loss': 6.6021881103515625}\n",
            "{'epoch': 6, 'batch': 86, 'loss': 6.322427272796631}\n",
            "{'epoch': 6, 'batch': 87, 'loss': 6.421983242034912}\n",
            "{'epoch': 6, 'batch': 88, 'loss': 6.267858028411865}\n",
            "{'epoch': 6, 'batch': 89, 'loss': 6.42238712310791}\n",
            "{'epoch': 6, 'batch': 90, 'loss': 6.923163890838623}\n",
            "{'epoch': 6, 'batch': 91, 'loss': 6.303378582000732}\n",
            "{'epoch': 6, 'batch': 92, 'loss': 6.50877571105957}\n",
            "{'epoch': 6, 'batch': 93, 'loss': 5.840404987335205}\n",
            "{'epoch': 7, 'batch': 0, 'loss': 6.445046901702881}\n",
            "{'epoch': 7, 'batch': 1, 'loss': 6.323636054992676}\n",
            "{'epoch': 7, 'batch': 2, 'loss': 6.350514888763428}\n",
            "{'epoch': 7, 'batch': 3, 'loss': 6.540715217590332}\n",
            "{'epoch': 7, 'batch': 4, 'loss': 6.440576553344727}\n",
            "{'epoch': 7, 'batch': 5, 'loss': 6.407707691192627}\n",
            "{'epoch': 7, 'batch': 6, 'loss': 6.989199161529541}\n",
            "{'epoch': 7, 'batch': 7, 'loss': 6.744307994842529}\n",
            "{'epoch': 7, 'batch': 8, 'loss': 6.6702561378479}\n",
            "{'epoch': 7, 'batch': 9, 'loss': 6.644670009613037}\n",
            "{'epoch': 7, 'batch': 10, 'loss': 6.705455303192139}\n",
            "{'epoch': 7, 'batch': 11, 'loss': 6.46201753616333}\n",
            "{'epoch': 7, 'batch': 12, 'loss': 6.603214740753174}\n",
            "{'epoch': 7, 'batch': 13, 'loss': 6.747760772705078}\n",
            "{'epoch': 7, 'batch': 14, 'loss': 6.332735538482666}\n",
            "{'epoch': 7, 'batch': 15, 'loss': 6.4726033210754395}\n",
            "{'epoch': 7, 'batch': 16, 'loss': 6.236256122589111}\n",
            "{'epoch': 7, 'batch': 17, 'loss': 6.413844585418701}\n",
            "{'epoch': 7, 'batch': 18, 'loss': 6.251369476318359}\n",
            "{'epoch': 7, 'batch': 19, 'loss': 6.434135437011719}\n",
            "{'epoch': 7, 'batch': 20, 'loss': 6.0321946144104}\n",
            "{'epoch': 7, 'batch': 21, 'loss': 6.594048976898193}\n",
            "{'epoch': 7, 'batch': 22, 'loss': 6.632582187652588}\n",
            "{'epoch': 7, 'batch': 23, 'loss': 6.6778483390808105}\n",
            "{'epoch': 7, 'batch': 24, 'loss': 6.67415189743042}\n",
            "{'epoch': 7, 'batch': 25, 'loss': 6.365564346313477}\n",
            "{'epoch': 7, 'batch': 26, 'loss': 6.120199680328369}\n",
            "{'epoch': 7, 'batch': 27, 'loss': 6.234745502471924}\n",
            "{'epoch': 7, 'batch': 28, 'loss': 6.782904624938965}\n",
            "{'epoch': 7, 'batch': 29, 'loss': 6.813178539276123}\n",
            "{'epoch': 7, 'batch': 30, 'loss': 6.032476902008057}\n",
            "{'epoch': 7, 'batch': 31, 'loss': 5.994060039520264}\n",
            "{'epoch': 7, 'batch': 32, 'loss': 6.158830165863037}\n",
            "{'epoch': 7, 'batch': 33, 'loss': 6.435920715332031}\n",
            "{'epoch': 7, 'batch': 34, 'loss': 6.35011625289917}\n",
            "{'epoch': 7, 'batch': 35, 'loss': 6.4972381591796875}\n",
            "{'epoch': 7, 'batch': 36, 'loss': 6.402945518493652}\n",
            "{'epoch': 7, 'batch': 37, 'loss': 6.279666423797607}\n",
            "{'epoch': 7, 'batch': 38, 'loss': 6.719461441040039}\n",
            "{'epoch': 7, 'batch': 39, 'loss': 6.436949729919434}\n",
            "{'epoch': 7, 'batch': 40, 'loss': 6.658777713775635}\n",
            "{'epoch': 7, 'batch': 41, 'loss': 6.199887275695801}\n",
            "{'epoch': 7, 'batch': 42, 'loss': 6.691987037658691}\n",
            "{'epoch': 7, 'batch': 43, 'loss': 6.2568817138671875}\n",
            "{'epoch': 7, 'batch': 44, 'loss': 6.2226338386535645}\n",
            "{'epoch': 7, 'batch': 45, 'loss': 6.372483730316162}\n",
            "{'epoch': 7, 'batch': 46, 'loss': 6.54551887512207}\n",
            "{'epoch': 7, 'batch': 47, 'loss': 6.901373386383057}\n",
            "{'epoch': 7, 'batch': 48, 'loss': 6.080202579498291}\n",
            "{'epoch': 7, 'batch': 49, 'loss': 6.546916961669922}\n",
            "{'epoch': 7, 'batch': 50, 'loss': 6.659914970397949}\n",
            "{'epoch': 7, 'batch': 51, 'loss': 6.676575660705566}\n",
            "{'epoch': 7, 'batch': 52, 'loss': 5.978850364685059}\n",
            "{'epoch': 7, 'batch': 53, 'loss': 6.380253791809082}\n",
            "{'epoch': 7, 'batch': 54, 'loss': 6.277238368988037}\n",
            "{'epoch': 7, 'batch': 55, 'loss': 6.244448184967041}\n",
            "{'epoch': 7, 'batch': 56, 'loss': 6.360013484954834}\n",
            "{'epoch': 7, 'batch': 57, 'loss': 6.308224201202393}\n",
            "{'epoch': 7, 'batch': 58, 'loss': 6.213099479675293}\n",
            "{'epoch': 7, 'batch': 59, 'loss': 6.337849140167236}\n",
            "{'epoch': 7, 'batch': 60, 'loss': 6.265679836273193}\n",
            "{'epoch': 7, 'batch': 61, 'loss': 6.356348514556885}\n",
            "{'epoch': 7, 'batch': 62, 'loss': 6.416737079620361}\n",
            "{'epoch': 7, 'batch': 63, 'loss': 6.257568836212158}\n",
            "{'epoch': 7, 'batch': 64, 'loss': 6.284628391265869}\n",
            "{'epoch': 7, 'batch': 65, 'loss': 6.310812950134277}\n",
            "{'epoch': 7, 'batch': 66, 'loss': 6.3868408203125}\n",
            "{'epoch': 7, 'batch': 67, 'loss': 6.0686140060424805}\n",
            "{'epoch': 7, 'batch': 68, 'loss': 6.272678852081299}\n",
            "{'epoch': 7, 'batch': 69, 'loss': 5.9278178215026855}\n",
            "{'epoch': 7, 'batch': 70, 'loss': 6.578177452087402}\n",
            "{'epoch': 7, 'batch': 71, 'loss': 6.395935535430908}\n",
            "{'epoch': 7, 'batch': 72, 'loss': 6.30695915222168}\n",
            "{'epoch': 7, 'batch': 73, 'loss': 6.292494773864746}\n",
            "{'epoch': 7, 'batch': 74, 'loss': 6.37505578994751}\n",
            "{'epoch': 7, 'batch': 75, 'loss': 6.442840099334717}\n",
            "{'epoch': 7, 'batch': 76, 'loss': 6.306477069854736}\n",
            "{'epoch': 7, 'batch': 77, 'loss': 6.547066688537598}\n",
            "{'epoch': 7, 'batch': 78, 'loss': 6.528865337371826}\n",
            "{'epoch': 7, 'batch': 79, 'loss': 5.9472832679748535}\n",
            "{'epoch': 7, 'batch': 80, 'loss': 6.112532615661621}\n",
            "{'epoch': 7, 'batch': 81, 'loss': 6.335541248321533}\n",
            "{'epoch': 7, 'batch': 82, 'loss': 6.325705528259277}\n",
            "{'epoch': 7, 'batch': 83, 'loss': 6.429642677307129}\n",
            "{'epoch': 7, 'batch': 84, 'loss': 6.373234748840332}\n",
            "{'epoch': 7, 'batch': 85, 'loss': 6.437163352966309}\n",
            "{'epoch': 7, 'batch': 86, 'loss': 6.162092685699463}\n",
            "{'epoch': 7, 'batch': 87, 'loss': 6.2601165771484375}\n",
            "{'epoch': 7, 'batch': 88, 'loss': 6.101984977722168}\n",
            "{'epoch': 7, 'batch': 89, 'loss': 6.264771938323975}\n",
            "{'epoch': 7, 'batch': 90, 'loss': 6.764005661010742}\n",
            "{'epoch': 7, 'batch': 91, 'loss': 6.1051025390625}\n",
            "{'epoch': 7, 'batch': 92, 'loss': 6.330017566680908}\n",
            "{'epoch': 7, 'batch': 93, 'loss': 5.660645961761475}\n",
            "{'epoch': 8, 'batch': 0, 'loss': 6.252753734588623}\n",
            "{'epoch': 8, 'batch': 1, 'loss': 6.120355129241943}\n",
            "{'epoch': 8, 'batch': 2, 'loss': 6.162656307220459}\n",
            "{'epoch': 8, 'batch': 3, 'loss': 6.362677574157715}\n",
            "{'epoch': 8, 'batch': 4, 'loss': 6.245850563049316}\n",
            "{'epoch': 8, 'batch': 5, 'loss': 6.225524425506592}\n",
            "{'epoch': 8, 'batch': 6, 'loss': 6.801990509033203}\n",
            "{'epoch': 8, 'batch': 7, 'loss': 6.572618007659912}\n",
            "{'epoch': 8, 'batch': 8, 'loss': 6.49534273147583}\n",
            "{'epoch': 8, 'batch': 9, 'loss': 6.476240158081055}\n",
            "{'epoch': 8, 'batch': 10, 'loss': 6.552019119262695}\n",
            "{'epoch': 8, 'batch': 11, 'loss': 6.258241653442383}\n",
            "{'epoch': 8, 'batch': 12, 'loss': 6.42747163772583}\n",
            "{'epoch': 8, 'batch': 13, 'loss': 6.571908473968506}\n",
            "{'epoch': 8, 'batch': 14, 'loss': 6.161193370819092}\n",
            "{'epoch': 8, 'batch': 15, 'loss': 6.3155198097229}\n",
            "{'epoch': 8, 'batch': 16, 'loss': 6.076338291168213}\n",
            "{'epoch': 8, 'batch': 17, 'loss': 6.2491774559021}\n",
            "{'epoch': 8, 'batch': 18, 'loss': 6.100744724273682}\n",
            "{'epoch': 8, 'batch': 19, 'loss': 6.286719799041748}\n",
            "{'epoch': 8, 'batch': 20, 'loss': 5.871968746185303}\n",
            "{'epoch': 8, 'batch': 21, 'loss': 6.440922260284424}\n",
            "{'epoch': 8, 'batch': 22, 'loss': 6.480283737182617}\n",
            "{'epoch': 8, 'batch': 23, 'loss': 6.544550895690918}\n",
            "{'epoch': 8, 'batch': 24, 'loss': 6.549003601074219}\n",
            "{'epoch': 8, 'batch': 25, 'loss': 6.23399019241333}\n",
            "{'epoch': 8, 'batch': 26, 'loss': 5.950150012969971}\n",
            "{'epoch': 8, 'batch': 27, 'loss': 6.059835910797119}\n",
            "{'epoch': 8, 'batch': 28, 'loss': 6.6198883056640625}\n",
            "{'epoch': 8, 'batch': 29, 'loss': 6.6941399574279785}\n",
            "{'epoch': 8, 'batch': 30, 'loss': 5.87016487121582}\n",
            "{'epoch': 8, 'batch': 31, 'loss': 5.838934421539307}\n",
            "{'epoch': 8, 'batch': 32, 'loss': 6.0124335289001465}\n",
            "{'epoch': 8, 'batch': 33, 'loss': 6.295820713043213}\n",
            "{'epoch': 8, 'batch': 34, 'loss': 6.170656681060791}\n",
            "{'epoch': 8, 'batch': 35, 'loss': 6.313086986541748}\n",
            "{'epoch': 8, 'batch': 36, 'loss': 6.2334089279174805}\n",
            "{'epoch': 8, 'batch': 37, 'loss': 6.111368179321289}\n",
            "{'epoch': 8, 'batch': 38, 'loss': 6.5509796142578125}\n",
            "{'epoch': 8, 'batch': 39, 'loss': 6.268617153167725}\n",
            "{'epoch': 8, 'batch': 40, 'loss': 6.485025882720947}\n",
            "{'epoch': 8, 'batch': 41, 'loss': 6.035726070404053}\n",
            "{'epoch': 8, 'batch': 42, 'loss': 6.499728202819824}\n",
            "{'epoch': 8, 'batch': 43, 'loss': 6.072116851806641}\n",
            "{'epoch': 8, 'batch': 44, 'loss': 6.045187473297119}\n",
            "{'epoch': 8, 'batch': 45, 'loss': 6.1942458152771}\n",
            "{'epoch': 8, 'batch': 46, 'loss': 6.365355968475342}\n",
            "{'epoch': 8, 'batch': 47, 'loss': 6.715808868408203}\n",
            "{'epoch': 8, 'batch': 48, 'loss': 5.903905868530273}\n",
            "{'epoch': 8, 'batch': 49, 'loss': 6.373214244842529}\n",
            "{'epoch': 8, 'batch': 50, 'loss': 6.477789402008057}\n",
            "{'epoch': 8, 'batch': 51, 'loss': 6.5266947746276855}\n",
            "{'epoch': 8, 'batch': 52, 'loss': 5.820284843444824}\n",
            "{'epoch': 8, 'batch': 53, 'loss': 6.214110851287842}\n",
            "{'epoch': 8, 'batch': 54, 'loss': 6.13145637512207}\n",
            "{'epoch': 8, 'batch': 55, 'loss': 6.0907769203186035}\n",
            "{'epoch': 8, 'batch': 56, 'loss': 6.195660591125488}\n",
            "{'epoch': 8, 'batch': 57, 'loss': 6.146255970001221}\n",
            "{'epoch': 8, 'batch': 58, 'loss': 6.088260650634766}\n",
            "{'epoch': 8, 'batch': 59, 'loss': 6.17195463180542}\n",
            "{'epoch': 8, 'batch': 60, 'loss': 6.113062858581543}\n",
            "{'epoch': 8, 'batch': 61, 'loss': 6.192183971405029}\n",
            "{'epoch': 8, 'batch': 62, 'loss': 6.295479774475098}\n",
            "{'epoch': 8, 'batch': 63, 'loss': 6.11481237411499}\n",
            "{'epoch': 8, 'batch': 64, 'loss': 6.16641092300415}\n",
            "{'epoch': 8, 'batch': 65, 'loss': 6.21627140045166}\n",
            "{'epoch': 8, 'batch': 66, 'loss': 6.277211666107178}\n",
            "{'epoch': 8, 'batch': 67, 'loss': 5.933818340301514}\n",
            "{'epoch': 8, 'batch': 68, 'loss': 6.157006740570068}\n",
            "{'epoch': 8, 'batch': 69, 'loss': 5.8095479011535645}\n",
            "{'epoch': 8, 'batch': 70, 'loss': 6.469917297363281}\n",
            "{'epoch': 8, 'batch': 71, 'loss': 6.256435394287109}\n",
            "{'epoch': 8, 'batch': 72, 'loss': 6.207006454467773}\n",
            "{'epoch': 8, 'batch': 73, 'loss': 6.1646904945373535}\n",
            "{'epoch': 8, 'batch': 74, 'loss': 6.240554332733154}\n",
            "{'epoch': 8, 'batch': 75, 'loss': 6.319714546203613}\n",
            "{'epoch': 8, 'batch': 76, 'loss': 6.171653747558594}\n",
            "{'epoch': 8, 'batch': 77, 'loss': 6.388394355773926}\n",
            "{'epoch': 8, 'batch': 78, 'loss': 6.399255275726318}\n",
            "{'epoch': 8, 'batch': 79, 'loss': 5.7834038734436035}\n",
            "{'epoch': 8, 'batch': 80, 'loss': 5.928229808807373}\n",
            "{'epoch': 8, 'batch': 81, 'loss': 6.193583965301514}\n",
            "{'epoch': 8, 'batch': 82, 'loss': 6.156139850616455}\n",
            "{'epoch': 8, 'batch': 83, 'loss': 6.2686896324157715}\n",
            "{'epoch': 8, 'batch': 84, 'loss': 6.223710536956787}\n",
            "{'epoch': 8, 'batch': 85, 'loss': 6.27241325378418}\n",
            "{'epoch': 8, 'batch': 86, 'loss': 5.97915506362915}\n",
            "{'epoch': 8, 'batch': 87, 'loss': 6.102928161621094}\n",
            "{'epoch': 8, 'batch': 88, 'loss': 5.957507610321045}\n",
            "{'epoch': 8, 'batch': 89, 'loss': 6.105835914611816}\n",
            "{'epoch': 8, 'batch': 90, 'loss': 6.584828853607178}\n",
            "{'epoch': 8, 'batch': 91, 'loss': 5.953601837158203}\n",
            "{'epoch': 8, 'batch': 92, 'loss': 6.155155658721924}\n",
            "{'epoch': 8, 'batch': 93, 'loss': 5.486222743988037}\n",
            "{'epoch': 9, 'batch': 0, 'loss': 6.065299987792969}\n",
            "{'epoch': 9, 'batch': 1, 'loss': 5.9224443435668945}\n",
            "{'epoch': 9, 'batch': 2, 'loss': 6.037012100219727}\n",
            "{'epoch': 9, 'batch': 3, 'loss': 6.222540855407715}\n",
            "{'epoch': 9, 'batch': 4, 'loss': 6.071243762969971}\n",
            "{'epoch': 9, 'batch': 5, 'loss': 6.068359851837158}\n",
            "{'epoch': 9, 'batch': 6, 'loss': 6.640313625335693}\n",
            "{'epoch': 9, 'batch': 7, 'loss': 6.424963474273682}\n",
            "{'epoch': 9, 'batch': 8, 'loss': 6.323132038116455}\n",
            "{'epoch': 9, 'batch': 9, 'loss': 6.302473545074463}\n",
            "{'epoch': 9, 'batch': 10, 'loss': 6.4041032791137695}\n",
            "{'epoch': 9, 'batch': 11, 'loss': 6.091802597045898}\n",
            "{'epoch': 9, 'batch': 12, 'loss': 6.261166095733643}\n",
            "{'epoch': 9, 'batch': 13, 'loss': 6.406772613525391}\n",
            "{'epoch': 9, 'batch': 14, 'loss': 5.9870381355285645}\n",
            "{'epoch': 9, 'batch': 15, 'loss': 6.168848991394043}\n",
            "{'epoch': 9, 'batch': 16, 'loss': 5.921082019805908}\n",
            "{'epoch': 9, 'batch': 17, 'loss': 6.0752387046813965}\n",
            "{'epoch': 9, 'batch': 18, 'loss': 5.940629005432129}\n",
            "{'epoch': 9, 'batch': 19, 'loss': 6.140851020812988}\n",
            "{'epoch': 9, 'batch': 20, 'loss': 5.698571681976318}\n",
            "{'epoch': 9, 'batch': 21, 'loss': 6.253859996795654}\n",
            "{'epoch': 9, 'batch': 22, 'loss': 6.3290629386901855}\n",
            "{'epoch': 9, 'batch': 23, 'loss': 6.414780616760254}\n",
            "{'epoch': 9, 'batch': 24, 'loss': 6.416201591491699}\n",
            "{'epoch': 9, 'batch': 25, 'loss': 6.066911220550537}\n",
            "{'epoch': 9, 'batch': 26, 'loss': 5.813684940338135}\n",
            "{'epoch': 9, 'batch': 27, 'loss': 5.8967084884643555}\n",
            "{'epoch': 9, 'batch': 28, 'loss': 6.490573406219482}\n",
            "{'epoch': 9, 'batch': 29, 'loss': 6.570056915283203}\n",
            "{'epoch': 9, 'batch': 30, 'loss': 5.724104404449463}\n",
            "{'epoch': 9, 'batch': 31, 'loss': 5.697696208953857}\n",
            "{'epoch': 9, 'batch': 32, 'loss': 5.896816730499268}\n",
            "{'epoch': 9, 'batch': 33, 'loss': 6.177386283874512}\n",
            "{'epoch': 9, 'batch': 34, 'loss': 6.00784969329834}\n",
            "{'epoch': 9, 'batch': 35, 'loss': 6.1660871505737305}\n",
            "{'epoch': 9, 'batch': 36, 'loss': 6.103000164031982}\n",
            "{'epoch': 9, 'batch': 37, 'loss': 5.9922261238098145}\n",
            "{'epoch': 9, 'batch': 38, 'loss': 6.412790298461914}\n",
            "{'epoch': 9, 'batch': 39, 'loss': 6.117027759552002}\n",
            "{'epoch': 9, 'batch': 40, 'loss': 6.339702606201172}\n",
            "{'epoch': 9, 'batch': 41, 'loss': 5.897231578826904}\n",
            "{'epoch': 9, 'batch': 42, 'loss': 6.367895603179932}\n",
            "{'epoch': 9, 'batch': 43, 'loss': 5.953121662139893}\n",
            "{'epoch': 9, 'batch': 44, 'loss': 5.932214260101318}\n",
            "{'epoch': 9, 'batch': 45, 'loss': 6.071089267730713}\n",
            "{'epoch': 9, 'batch': 46, 'loss': 6.234378337860107}\n",
            "{'epoch': 9, 'batch': 47, 'loss': 6.5926513671875}\n",
            "{'epoch': 9, 'batch': 48, 'loss': 5.772538661956787}\n",
            "{'epoch': 9, 'batch': 49, 'loss': 6.249368190765381}\n",
            "{'epoch': 9, 'batch': 50, 'loss': 6.3468756675720215}\n",
            "{'epoch': 9, 'batch': 51, 'loss': 6.415426731109619}\n",
            "{'epoch': 9, 'batch': 52, 'loss': 5.7080793380737305}\n",
            "{'epoch': 9, 'batch': 53, 'loss': 6.0409321784973145}\n",
            "{'epoch': 9, 'batch': 54, 'loss': 5.984058856964111}\n",
            "{'epoch': 9, 'batch': 55, 'loss': 5.922440052032471}\n",
            "{'epoch': 9, 'batch': 56, 'loss': 6.044632434844971}\n",
            "{'epoch': 9, 'batch': 57, 'loss': 6.0057806968688965}\n",
            "{'epoch': 9, 'batch': 58, 'loss': 5.927463054656982}\n",
            "{'epoch': 9, 'batch': 59, 'loss': 6.028929233551025}\n",
            "{'epoch': 9, 'batch': 60, 'loss': 5.962871551513672}\n",
            "{'epoch': 9, 'batch': 61, 'loss': 6.01509428024292}\n",
            "{'epoch': 9, 'batch': 62, 'loss': 6.124296188354492}\n",
            "{'epoch': 9, 'batch': 63, 'loss': 5.9377241134643555}\n",
            "{'epoch': 9, 'batch': 64, 'loss': 5.976752758026123}\n",
            "{'epoch': 9, 'batch': 65, 'loss': 6.043969631195068}\n",
            "{'epoch': 9, 'batch': 66, 'loss': 6.1300787925720215}\n",
            "{'epoch': 9, 'batch': 67, 'loss': 5.770632266998291}\n",
            "{'epoch': 9, 'batch': 68, 'loss': 5.997727394104004}\n",
            "{'epoch': 9, 'batch': 69, 'loss': 5.6813154220581055}\n",
            "{'epoch': 9, 'batch': 70, 'loss': 6.290503978729248}\n",
            "{'epoch': 9, 'batch': 71, 'loss': 6.062743186950684}\n",
            "{'epoch': 9, 'batch': 72, 'loss': 6.044616222381592}\n",
            "{'epoch': 9, 'batch': 73, 'loss': 5.992668628692627}\n",
            "{'epoch': 9, 'batch': 74, 'loss': 6.087837219238281}\n",
            "{'epoch': 9, 'batch': 75, 'loss': 6.170097827911377}\n",
            "{'epoch': 9, 'batch': 76, 'loss': 6.0557756423950195}\n",
            "{'epoch': 9, 'batch': 77, 'loss': 6.212647914886475}\n",
            "{'epoch': 9, 'batch': 78, 'loss': 6.2393035888671875}\n",
            "{'epoch': 9, 'batch': 79, 'loss': 5.611981391906738}\n",
            "{'epoch': 9, 'batch': 80, 'loss': 5.7897210121154785}\n",
            "{'epoch': 9, 'batch': 81, 'loss': 6.0533270835876465}\n",
            "{'epoch': 9, 'batch': 82, 'loss': 6.016404151916504}\n",
            "{'epoch': 9, 'batch': 83, 'loss': 6.1548614501953125}\n",
            "{'epoch': 9, 'batch': 84, 'loss': 6.126069068908691}\n",
            "{'epoch': 9, 'batch': 85, 'loss': 6.158782958984375}\n",
            "{'epoch': 9, 'batch': 86, 'loss': 5.841301441192627}\n",
            "{'epoch': 9, 'batch': 87, 'loss': 5.974477767944336}\n",
            "{'epoch': 9, 'batch': 88, 'loss': 5.799436092376709}\n",
            "{'epoch': 9, 'batch': 89, 'loss': 5.94744348526001}\n",
            "{'epoch': 9, 'batch': 90, 'loss': 6.458518028259277}\n",
            "{'epoch': 9, 'batch': 91, 'loss': 5.834911346435547}\n",
            "{'epoch': 9, 'batch': 92, 'loss': 6.052785873413086}\n",
            "{'epoch': 9, 'batch': 93, 'loss': 5.402435779571533}\n",
            "['One', 'day', 'I', 'shot', 'an', 'elephant', 'in', 'my', 'suit.', 'I', 'have', 'no', 'idea', 'how', 'he', 'got', 'into', 'it.', 'being', 'pass', 'carrot', '****', 'story', 'one', 'all', 'I', 'place', 'no', 'feet?', 'alive?', 'could', 'go', 'into', 'one', 'walk?', 'in', 'allow', 'trip', 'and', 'who?**', 'for', 'asking', 'A', 'Why', 'about', 'the', 'mayor', 'What', 'go', 'you', 'back?', 'ingesting', 'years.', 'I', 'I', 'in', 'the', 'centipede', 'You', 'let', 'a', 'there?', 'Why', 'is', 'nose', 'They', 'no', 'anything.', 'came', 'had', 'really', 'college?', 'from', 'a', 'scientist', 'knight?', 'What', 'you', 'gold', 'youre', 'a', 'dirty', 'bone?', 'favorite', 'into', 'got', 'Christmas', 'but', 'in', 'a', 'corn', \"I'll\", 'zoo...', 'for', 'a', 'Like', 'complex.', 'Joke', 'What', 'do', 'you', 'call', 'the', 'legs?', 'Superman', 'it', 'it', 'he', 'celebrity', 'his', 'what', 'off.', 'how', 'Do', 'you', 'earth', 'woke', 'Well,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Exercises \n",
        "\n",
        "1.  Nous allons essayer d'améliorer les résultats de notre réseau récurrent. Essayez de changer la taille de la représentation cachée (hidden representation size). Les résultats sont-ils meilleurs ?"
      ],
      "metadata": {
        "id": "CTad20L1xHwD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uzE7WGnHxkuF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Essayez d'expérimenter avec une couche récurrente supplémentaire. Avez-vous obtenu de meilleurs résultats ? "
      ],
      "metadata": {
        "id": "38mhNK_mxlRz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GzFjoiGxqLZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Expérimentez également avec le dropout rate et essayez de voir si vos résultats sont meilleurs. "
      ],
      "metadata": {
        "id": "_EKT_ojv7sIR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1oPxi81W7u2g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Transformez le LSTM en un LSTM bidirectionnel \n"
      ],
      "metadata": {
        "id": "CJNSMACkE6CO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xgpSvjRJFPzI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. La fonction `predict` choisit aléatoirement, selon la distribution des probabilités, un mot. Essayez de faire la même chose, mais en se limitant sur les 4 mots les plus probables. Autrement dit, utilisez une distribution de probabilités uniforme sur ces 4 mots. Les résultats se sont-ils améliorés ? Que doit-on faire pour les améliorer encore ?\n",
        "\n"
      ],
      "metadata": {
        "id": "0DOjLHSAPguS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "    words = text.split(' ')\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach()#.numpy()\n",
        "        # saving the indices of topk which records 4 words with best prob\n",
        "        best_prob = torch.topk(p, 4).indices \n",
        "        word_index = np.random.choice(best_prob)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "    return words\n",
        "\n",
        "print(predict(dataset, model, text='One day I shot an elephant in my suit. I have no idea how he got into it.', next_words = 2))"
      ],
      "metadata": {
        "id": "Bno8VCGcPwjl",
        "outputId": "de6446ac-d664-417b-a5a3-3857d8e96531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['One', 'day', 'I', 'shot', 'an', 'elephant', 'in', 'my', 'suit.', 'I', 'have', 'no', 'idea', 'how', 'he', 'got', 'into', 'it.', 'and', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Vous pouvez télécharger un autre jeu de données, des recettes de cuisine. Tester le modèle sur ces nouvelles données."
      ],
      "metadata": {
        "id": "6GhVuQHtADBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.irit.fr/~Thomas.Pellegrini/ens/M1ML1/sents_recipes.txt"
      ],
      "metadata": {
        "id": "C-bt8alRAVpd",
        "outputId": "24b9e615-2d7f-4f40-bb7e-c77573d19409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-13 12:58:26--  https://www.irit.fr/~Thomas.Pellegrini/ens/M1ML1/sents_recipes.txt\n",
            "Resolving www.irit.fr (www.irit.fr)... 141.115.28.2\n",
            "Connecting to www.irit.fr (www.irit.fr)|141.115.28.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘sents_recipes.txt’\n",
            "\n",
            "sents_recipes.txt       [   <=>              ] 574.38K   581KB/s    in 1.0s    \n",
            "\n",
            "2023-02-13 12:58:29 (581 KB/s) - ‘sents_recipes.txt’ saved [588160]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Voici un troisième jeu de données : une liste de noms de villes françaises. Cette fois-ci, l'idée est de travailler au niveau des caractères plutôt que des mots. Modifier le notebook pour gérer les caractères. La taille de la séquence à modéliser peut être plus grande que pour les mots. \n"
      ],
      "metadata": {
        "id": "3uDj2YW-AYXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.irit.fr/~Thomas.Pellegrini/ens/M1ML1/communes_france.txt"
      ],
      "metadata": {
        "id": "fuq-FtVoA9T8",
        "outputId": "4437833f-8dd2-4718-a42f-c7a1a407587c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-13 12:58:29--  https://www.irit.fr/~Thomas.Pellegrini/ens/M1ML1/communes_france.txt\n",
            "Resolving www.irit.fr (www.irit.fr)... 141.115.28.2\n",
            "Connecting to www.irit.fr (www.irit.fr)|141.115.28.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘communes_france.txt’\n",
            "\n",
            "communes_france.txt     [   <=>              ] 434.20K   556KB/s    in 0.8s    \n",
            "\n",
            "2023-02-13 12:58:30 (556 KB/s) - ‘communes_france.txt’ saved [444616]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}